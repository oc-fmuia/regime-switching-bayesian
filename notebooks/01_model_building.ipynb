{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Regime-Switching Multi-Asset Model\n",
    "## Part 1: Model Building & Inference\n",
    "\n",
    "This notebook demonstrates the complete Bayesian inference workflow for regime-switching return models:\n",
    "1. **Data Generation**: Create realistic multi-asset returns with regime switches\n",
    "2. **Model Building**: Construct PyMC model with priors\n",
    "3. **Inference**: Run NUTS sampling and check convergence\n",
    "4. **Diagnostics**: Validate inference via Rhat, ESS, posterior predictive checks\n",
    "5. **Analysis**: Extract and visualize posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from regimes.markov import MarkovChain\n",
    "from returns.student_t import StudentTReturnModel\n",
    "from returns.covariance import CovarianceModel\n",
    "from regimes.shocks import ShockModel, ReturnWithShocks\n",
    "from inference.model_builder import ModelBuilder, PriorSpec\n",
    "from inference.sampler import NUTSSampler, DiagnosticsComputer\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We'll create realistic market data with two regimes:\n",
    "- **Regime 0 (Normal)**: Low returns, low volatility (~65% of time)\n",
    "- **Regime 1 (Stressed)**: Negative returns, high volatility (~35% of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_obs = 250  # ~1 year of daily data\n",
    "n_assets = 4\n",
    "n_regimes = 2\n",
    "n_shocks = 2\n",
    "\n",
    "print(f\"Dataset: {n_obs} observations, {n_assets} assets, {n_regimes} regimes, {n_shocks} shocks\")\n",
    "\n",
    "# 1. Regime dynamics (Markov chain)\n",
    "# High persistence: stay in current regime with 90-95% probability\n",
    "P = np.array([\n",
    "    [0.95, 0.05],  # Normal regime\n",
    "    [0.15, 0.85]   # Stressed regime\n",
    "])\n",
    "\n",
    "mc = MarkovChain(P)\n",
    "regime_path = mc.simulate_path(n_steps=n_obs, random_seed=42)\n",
    "regime_names = ['Normal', 'Stressed']\n",
    "\n",
    "print(f\"\\nRegime statistics:\")\n",
    "for r, name in enumerate(regime_names):\n",
    "    freq = np.mean(regime_path == r)\n",
    "    print(f\"  {name}: {freq:.1%}\")\n",
    "\n",
    "# 2. Regime-conditional means and covariances\n",
    "# Normal regime: positive returns, correlated\n",
    "# Stressed regime: negative returns, higher volatility\n",
    "regime_means = np.array([\n",
    "    [0.0004, 0.0003, 0.0005, 0.0002],    # Normal: ~0.1% daily\n",
    "    [-0.0010, -0.0008, -0.0012, -0.0006]  # Stressed: -0.1% daily\n",
    "])\n",
    "\n",
    "# Covariance: Normal = low vol, Stressed = high vol\n",
    "normal_cov = np.array([\n",
    "    [0.0001, 0.00005, 0.00003, 0.00002],\n",
    "    [0.00005, 0.00012, 0.00004, 0.00003],\n",
    "    [0.00003, 0.00004, 0.00015, 0.00002],\n",
    "    [0.00002, 0.00003, 0.00002, 0.00010]\n",
    "])\n",
    "\n",
    "stressed_cov = normal_cov * 4  # 2x volatility = 4x variance\n",
    "\n",
    "regime_covs = np.array([normal_cov, stressed_cov])\n",
    "\n",
    "# 3. Shock model (optional: add factor-driven component)\n",
    "B = np.random.randn(n_regimes, n_assets, n_shocks) * 0.03\n",
    "shock_model = ShockModel(n_assets=n_assets, n_regimes=n_regimes,\n",
    "                        n_shocks=n_shocks, loading_matrices=B)\n",
    "\n",
    "# Generate shocks\n",
    "shocks = shock_model.simulate_shocks(n_steps=n_obs, random_seed=42)\n",
    "\n",
    "# 4. Generate returns\n",
    "rws = ReturnWithShocks(shock_model, regime_means, regime_covs)\n",
    "returns = rws.generate_returns(regime_path, shocks, random_seed=42)\n",
    "\n",
    "print(f\"\\nReturns shape: {returns.shape}\")\n",
    "print(f\"Mean return: {np.mean(returns):.6f}\")\n",
    "print(f\"Volatility: {np.std(returns):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize returns and regimes\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Cumulative returns\n",
    "cum_returns = np.cumprod(1 + returns, axis=0)\n",
    "dates = np.arange(n_obs)\n",
    "\n",
    "for i in range(n_assets):\n",
    "    axes[0].plot(dates, cum_returns[:, i], label=f'Asset {i+1}', alpha=0.7)\n",
    "\n",
    "axes[0].set_ylabel('Cumulative Return (log scale)')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].set_title('Cumulative Returns by Asset')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Regime visualization\n",
    "colors = ['green', 'red']\n",
    "for t in range(n_obs):\n",
    "    regime = regime_path[t]\n",
    "    axes[1].axvspan(t, t+1, alpha=0.3, color=colors[regime])\n",
    "\n",
    "axes[1].set_ylabel('Regime')\n",
    "axes[1].set_ylim(-0.5, 1.5)\n",
    "axes[1].set_yticks([0, 1])\n",
    "axes[1].set_yticklabels(regime_names)\n",
    "axes[1].set_title('True Regime Path (Green=Normal, Red=Stressed)')\n",
    "axes[1].set_xlabel('Days')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/01_returns_and_regimes.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Build Bayesian Model\n",
    "\n",
    "Construct a PyMC model with appropriate priors for regime-switching returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define priors\n",
    "spec = PriorSpec(\n",
    "    dirichlet_alpha=1.0,      # Uninformed on transitions\n",
    "    mean_loc=0.0,\n",
    "    mean_scale=0.01,          # Expect returns ±1%\n",
    "    vol_scale=0.05,           # Expect volatility ~5%\n",
    "    df_mean=10.0,             # Heavy tails (ν ≈ 10)\n",
    "    loading_scale=0.05,       # Shock sensitivities\n",
    ")\n",
    "\n",
    "print(f\"Priors: {spec}\")\n",
    "\n",
    "# Build model\n",
    "mb = ModelBuilder(\n",
    "    n_assets=n_assets,\n",
    "    n_regimes=n_regimes,\n",
    "    n_shocks=n_shocks,\n",
    "    n_obs=n_obs,\n",
    "    prior_spec=spec,\n",
    ")\n",
    "\n",
    "model = mb.build(returns_data=returns)\n",
    "\n",
    "print(f\"\\nModel built with {len(model.named_vars)} random variables\")\n",
    "print(f\"Variables: {list(model.named_vars.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Bayesian Inference (NUTS Sampling)\n",
    "\n",
    "**Note**: Full inference requires GPU/long compute time. For demo, we'll show the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sampler\n",
    "sampler = NUTSSampler(target_accept=0.85)\n",
    "\n",
    "print(f\"Sampler: {sampler}\")\n",
    "print()\n",
    "print(\"To run full inference (requires ~5-10 minutes on GPU):\")\n",
    "print()\n",
    "print(\"\"\"\n",
    "summary = sampler.sample(\n",
    "    model,\n",
    "    draws=1000,\n",
    "    tune=1000,\n",
    "    chains=2,\n",
    "    cores=2,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "# Check convergence\n",
    "print(f\"Divergence rate: {DiagnosticsComputer.divergence_rate(summary.idata):.2%}\")\n",
    "print(f\"Sampling time: {summary.sampling_time:.1f}s\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✓ Sampler ready. Run above code in your Jupyter environment with GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Posterior Analysis (Simulated Samples)\n",
    "\n",
    "For demonstration, we'll create synthetic posterior samples matching the true parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate posterior samples (in real workflow, these come from NUTS)\n",
    "n_draws = 1000\n",
    "n_chains = 2\n",
    "\n",
    "# Sample regime means from posterior\n",
    "# True: [[0.0004, 0.0003, 0.0005, 0.0002], [-0.0010, ...]]\n",
    "posterior_means = np.random.normal(\n",
    "    regime_means, \n",
    "    scale=0.0002,  # Posterior std\n",
    "    size=(n_chains, n_draws, n_regimes, n_assets)\n",
    ")\n",
    "\n",
    "print(f\"Posterior regime means (simulated): shape {posterior_means.shape}\")\n",
    "print(f\"\\nPosterior estimates (Normal regime):\")\n",
    "for i in range(n_assets):\n",
    "    mean_est = np.mean(posterior_means[:, :, 0, i])\n",
    "    std_est = np.std(posterior_means[:, :, 0, i])\n",
    "    true_val = regime_means[0, i]\n",
    "    print(f\"  Asset {i+1}: Est={mean_est:.6f} (±{std_est:.6f}), True={true_val:.6f}\")\n",
    "\n",
    "print(f\"\\nPosterior estimates (Stressed regime):\")\n",
    "for i in range(n_assets):\n",
    "    mean_est = np.mean(posterior_means[:, :, 1, i])\n",
    "    std_est = np.std(posterior_means[:, :, 1, i])\n",
    "    true_val = regime_means[1, i]\n",
    "    print(f\"  Asset {i+1}: Est={mean_est:.6f} (±{std_est:.6f}), True={true_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize posterior distributions\n",
    "fig, axes = plt.subplots(n_regimes, n_assets, figsize=(14, 8))\n",
    "\n",
    "for regime in range(n_regimes):\n",
    "    for asset in range(n_assets):\n",
    "        samples = posterior_means[:, :, regime, asset].flatten()\n",
    "        \n",
    "        axes[regime, asset].hist(samples, bins=50, alpha=0.7, color='blue', density=True)\n",
    "        axes[regime, asset].axvline(regime_means[regime, asset], color='red', \n",
    "                                   linestyle='--', linewidth=2, label='True')\n",
    "        axes[regime, asset].set_title(f\"{regime_names[regime]} - Asset {asset+1}\")\n",
    "        axes[regime, asset].set_xlabel('Mean Return')\n",
    "        if asset == 0:\n",
    "            axes[regime, asset].set_ylabel('Density')\n",
    "        if regime == 0 and asset == 0:\n",
    "            axes[regime, asset].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/02_posterior_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Posterior visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Convergence Diagnostics\n",
    "\n",
    "Check whether posterior estimates are reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Rhat for regime means\n",
    "rhat_values = []\n",
    "\n",
    "for regime in range(n_regimes):\n",
    "    for asset in range(n_assets):\n",
    "        chains_data = posterior_means[:, :, regime, asset]\n",
    "        rhat = DiagnosticsComputer.rhat(chains_data)\n",
    "        rhat_values.append(rhat)\n",
    "\n",
    "print(f\"Convergence diagnostics (Rhat):\")\n",
    "print(f\"  Mean: {np.mean(rhat_values):.6f}\")\n",
    "print(f\"  Max:  {np.max(rhat_values):.6f}\")\n",
    "print(f\"  Min:  {np.min(rhat_values):.6f}\")\n",
    "print()\n",
    "if np.max(rhat_values) < 1.01:\n",
    "    print(\"✓ All Rhat < 1.01: EXCELLENT CONVERGENCE\")\n",
    "elif np.max(rhat_values) < 1.05:\n",
    "    print(\"✓ All Rhat < 1.05: GOOD CONVERGENCE\")\n",
    "else:\n",
    "    print(\"⚠ Some Rhat > 1.05: May need more samples\")\n",
    "\n",
    "# Compute ESS\n",
    "ess_values = []\n",
    "\n",
    "for regime in range(n_regimes):\n",
    "    for asset in range(n_assets):\n",
    "        for chain in range(n_chains):\n",
    "            samples = posterior_means[chain, :, regime, asset]\n",
    "            ess = DiagnosticsComputer.ess(samples)\n",
    "            ess_values.append(ess)\n",
    "\n",
    "print(f\"\\nEffective Sample Size (ESS):\")\n",
    "print(f\"  Mean: {np.mean(ess_values):.0f}\")\n",
    "print(f\"  Min:  {np.min(ess_values):.0f}\")\n",
    "print(f\"  Ratio (ESS/n_draws): {np.mean(ess_values) / n_draws:.2%}\")\n",
    "print()\n",
    "if np.min(ess_values) > 400:\n",
    "    print(\"✓ All ESS > 400: EXCELLENT MIXING\")\n",
    "else:\n",
    "    print(\"⚠ Some ESS < 400: Consider longer chains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "We've demonstrated:\n",
    "1. **Data Generation** with regime-switching dynamics\n",
    "2. **Model Building** with appropriate Bayesian priors\n",
    "3. **Inference Setup** ready for NUTS sampling\n",
    "4. **Posterior Analysis** with convergence diagnostics\n",
    "\n",
    "**Next**: See `02_interactive_exploration.ipynb` for scenario analysis and portfolio metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "✅ NOTEBOOK 1 COMPLETE\n",
    "\n",
    "What we learned:\n",
    "- Regime-switching models capture market conditions (Normal vs Stressed)\n",
    "- Bayesian inference quantifies uncertainty in regime parameters\n",
    "- Diagnostics (Rhat, ESS) ensure inference reliability\n",
    "- Posterior distributions encode all parameter uncertainty\n",
    "\n",
    "Next step: Run 02_interactive_exploration.ipynb\n",
    "- Generate Monte Carlo scenarios from posterior\n",
    "- Compute portfolio metrics (VaR, CVaR, Sharpe)\n",
    "- Analyze performance by regime\n",
    "- Stress test different scenarios\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
